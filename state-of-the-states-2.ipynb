{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import csv, requests, os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from Google sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying Doc: https://docs.google.com/spreadsheets/d/1bvRKCfu9iGllHsOolDjMtbGA_2COddQFoZ7I45Lyn6o/edit#gid=0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>State</th>\n",
       "      <th>Governor</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Party</th>\n",
       "      <th>Type of Speech</th>\n",
       "      <th>New Gov?</th>\n",
       "      <th>2020 Contender?</th>\n",
       "      <th>Region</th>\n",
       "      <th>Trifecta Status</th>\n",
       "      <th>Trifecta</th>\n",
       "      <th>Best Transcript URL</th>\n",
       "      <th>Selector</th>\n",
       "      <th>Note</th>\n",
       "      <th>Lesser Transcript URL</th>\n",
       "      <th>New Best Transcript URL</th>\n",
       "      <th>filepath</th>\n",
       "      <th>file_exists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama_Inaugural.txt</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Kay Ivey</td>\n",
       "      <td>Female</td>\n",
       "      <td>R</td>\n",
       "      <td>Inaugural</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>South</td>\n",
       "      <td>R trifecta</td>\n",
       "      <td>Trifecta</td>\n",
       "      <td>https://governor.alabama.gov/remarks-speeches/...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.al.com/news/2019/01/the-full-text-...</td>\n",
       "      <td></td>\n",
       "      <td>speeches/Alabama_Inaugural.txt</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama_SOTS.txt</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Kay Ivey</td>\n",
       "      <td>Female</td>\n",
       "      <td>R</td>\n",
       "      <td>State of the state</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>South</td>\n",
       "      <td>R trifecta</td>\n",
       "      <td>Trifecta</td>\n",
       "      <td>https://governor.alabama.gov/remarks-speeches/...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://governor.alabama.gov/remarks-speeches/...</td>\n",
       "      <td>speeches/Alabama_SOTS.txt</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alaska_SOTS.txt</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>Mike Dunleavy</td>\n",
       "      <td>Male</td>\n",
       "      <td>R</td>\n",
       "      <td>State of the state</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>West</td>\n",
       "      <td>Divided government</td>\n",
       "      <td>Divided</td>\n",
       "      <td>https://gov.alaska.gov/newsroom/2019/01/22/201...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.adn.com/politics/2019/01/23/watch-...</td>\n",
       "      <td>https://gov.alaska.gov/newsroom/2019/01/22/201...</td>\n",
       "      <td>speeches/Alaska_SOTS.txt</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arizona_Inaugural.txt</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Doug Ducey</td>\n",
       "      <td>Male</td>\n",
       "      <td>R</td>\n",
       "      <td>Inaugural</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>West</td>\n",
       "      <td>R trifecta</td>\n",
       "      <td>Trifecta</td>\n",
       "      <td>https://azgovernor.gov/governor/news/2019/01/g...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>speeches/Arizona_Inaugural.txt</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Arizona_SOTS.txt</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Doug Ducey</td>\n",
       "      <td>Male</td>\n",
       "      <td>R</td>\n",
       "      <td>State of the state</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>West</td>\n",
       "      <td>R trifecta</td>\n",
       "      <td>Trifecta</td>\n",
       "      <td>https://azgovernor.gov/governor/news/2019/01/g...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://azgovernor.gov/governor/news/2019/01/g...</td>\n",
       "      <td>speeches/Arizona_SOTS.txt</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Filename    State       Governor  Gender Party  \\\n",
       "0  Alabama_Inaugural.txt  Alabama       Kay Ivey  Female     R   \n",
       "1       Alabama_SOTS.txt  Alabama       Kay Ivey  Female     R   \n",
       "3        Alaska_SOTS.txt   Alaska  Mike Dunleavy    Male     R   \n",
       "4  Arizona_Inaugural.txt  Arizona     Doug Ducey    Male     R   \n",
       "5       Arizona_SOTS.txt  Arizona     Doug Ducey    Male     R   \n",
       "\n",
       "       Type of Speech New Gov? 2020 Contender? Region     Trifecta Status  \\\n",
       "0           Inaugural       No              No  South          R trifecta   \n",
       "1  State of the state       No              No  South          R trifecta   \n",
       "3  State of the state      Yes              No   West  Divided government   \n",
       "4           Inaugural       No              No   West          R trifecta   \n",
       "5  State of the state       No              No   West          R trifecta   \n",
       "\n",
       "   Trifecta                                Best Transcript URL Selector Note  \\\n",
       "0  Trifecta  https://governor.alabama.gov/remarks-speeches/...                 \n",
       "1  Trifecta  https://governor.alabama.gov/remarks-speeches/...                 \n",
       "3   Divided  https://gov.alaska.gov/newsroom/2019/01/22/201...                 \n",
       "4  Trifecta  https://azgovernor.gov/governor/news/2019/01/g...                 \n",
       "5  Trifecta  https://azgovernor.gov/governor/news/2019/01/g...                 \n",
       "\n",
       "                               Lesser Transcript URL  \\\n",
       "0  https://www.al.com/news/2019/01/the-full-text-...   \n",
       "1                                                      \n",
       "3  https://www.adn.com/politics/2019/01/23/watch-...   \n",
       "4                                                      \n",
       "5                                                      \n",
       "\n",
       "                             New Best Transcript URL  \\\n",
       "0                                                      \n",
       "1  https://governor.alabama.gov/remarks-speeches/...   \n",
       "3  https://gov.alaska.gov/newsroom/2019/01/22/201...   \n",
       "4                                                      \n",
       "5  https://azgovernor.gov/governor/news/2019/01/g...   \n",
       "\n",
       "                         filepath  file_exists  \n",
       "0  speeches/Alabama_Inaugural.txt         True  \n",
       "1       speeches/Alabama_SOTS.txt         True  \n",
       "3        speeches/Alaska_SOTS.txt         True  \n",
       "4  speeches/Arizona_Inaugural.txt         True  \n",
       "5       speeches/Arizona_SOTS.txt         True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_regular_gsheet_url(doc_id, sheet_id):\n",
    "    return f\"https://docs.google.com/spreadsheets/d/{doc_id}/edit#gid={sheet_id}\"\n",
    "\n",
    "def make_csv_gsheet_url(doc_id, sheet_id):\n",
    "    return f\"https://docs.google.com/spreadsheets/d/{doc_id}/export?format=csv&id={doc_id}&gid={sheet_id}\"\n",
    "\n",
    "\n",
    "GOOGLE_SHEET_ID = '1bvRKCfu9iGllHsOolDjMtbGA_2COddQFoZ7I45Lyn6o'\n",
    "print(\"Querying Doc:\", make_regular_gsheet_url(GOOGLE_SHEET_ID, \"0\"))\n",
    "response = requests.get(make_csv_gsheet_url(GOOGLE_SHEET_ID, \"0\"))\n",
    "reader = csv.reader(response.text.splitlines())\n",
    "header = next(reader)\n",
    "df = pd.DataFrame(list(reader), columns=header)\n",
    "\n",
    "# Remove rows when N/A is a filename\n",
    "df = df[df['Filename'] != 'N/A']\n",
    "df['filepath'] = 'speeches/' + df.Filename\n",
    "df['file_exists'] = df['filepath'].apply(lambda x: os.path.isfile(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dataset is 50 speeches'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['Type of Speech'].isin(['State of the state','Both'])]\n",
    "f\"Dataset is {len(df)} speeches\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speeches(df):\n",
    "    speeches = []\n",
    "    for path in df['filepath']:\n",
    "        with open(path) as f:\n",
    "            text = f.read()\n",
    "            speeches.append(text)\n",
    "    return speeches\n",
    "\n",
    "speeches = get_speeches(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize, Train and Test\n",
    "\n",
    "Do all three together in one cell. Edit the parameters and re-run. \n",
    "\n",
    "See how making different methodological choices for features impacts your model accuracy and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "## YOU CAN EDIT THESE ðŸ‘ˆ\n",
    "y_columns = ['Party', 'Trifecta']\n",
    "BINARY=False\n",
    "NGRAM_RANGE=(1,1)\n",
    "MIN_DF=0.1\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "        stop_words='english', # 'english' if not custom list\n",
    "        ngram_range=NGRAM_RANGE,\n",
    "        binary=BINARY,\n",
    "        min_df=MIN_DF\n",
    "    )\n",
    "X = vectorizer.fit_transform(speeches)\n",
    "y = np.array(df['Party'])\n",
    "# 1 is Republican\n",
    "y = (y == 'R').astype('int') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  test_precision  test_recall  test_f1\n",
       "0       0.0         0.0           0.54            0.54         1.00     0.70\n",
       "1       0.0         0.0           0.54            0.55         0.86     0.67\n",
       "2       0.0         0.0           0.75            0.70         1.00     0.82\n",
       "3       0.0         0.0           0.75            0.71         0.83     0.77"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "test_accuracy     0.64\n",
       "test_precision    0.62\n",
       "test_recall       0.92\n",
       "test_f1           0.74\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train Classifier\n",
    "clf = MultinomialNB(alpha=1.0e-10, class_prior=None, fit_prior=True)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Test Classifier\n",
    "# 5-fold cross-validation\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "scores = cross_validate(clf, X, y, scoring=scoring, cv=4)\n",
    "display(pd.DataFrame(scores).round(2))\n",
    "\n",
    "pd.DataFrame(scores)[\n",
    "    ['test_accuracy','test_precision','test_recall','test_f1']]\\\n",
    "    .mean().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peek inside the model (coeffeicients on each word)\n",
    "\n",
    "https://fivethirtyeight.com/features/what-americas-governors-are-talking-about/\n",
    "\n",
    "see \"state-of-the-states.ipynb\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_count</th>\n",
       "      <th>r_count</th>\n",
       "      <th>d_log_proba</th>\n",
       "      <th>r_log_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hungry</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.752371</td>\n",
       "      <td>-33.750725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consequences</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.464689</td>\n",
       "      <td>-33.750725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ranks</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.752371</td>\n",
       "      <td>-33.750725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alliance</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.934692</td>\n",
       "      <td>-33.750725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equity</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.346906</td>\n",
       "      <td>-33.750725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bargain</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.934692</td>\n",
       "      <td>-33.750725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shutdown</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.598220</td>\n",
       "      <td>-33.750725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.752371</td>\n",
       "      <td>-33.750725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reproductive</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.598220</td>\n",
       "      <td>-33.750725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.241545</td>\n",
       "      <td>-33.750725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              d_count  r_count  d_log_proba  r_log_proba\n",
       "hungry            6.0      0.0    -8.752371   -33.750725\n",
       "consequences      8.0      0.0    -8.464689   -33.750725\n",
       "ranks             6.0      0.0    -8.752371   -33.750725\n",
       "alliance          5.0      0.0    -8.934692   -33.750725\n",
       "equity            9.0      0.0    -8.346906   -33.750725\n",
       "bargain           5.0      0.0    -8.934692   -33.750725\n",
       "shutdown          7.0      0.0    -8.598220   -33.750725\n",
       "2025              6.0      0.0    -8.752371   -33.750725\n",
       "reproductive      7.0      0.0    -8.598220   -33.750725\n",
       "color            10.0      0.0    -8.241545   -33.750725"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.concatenate((clf.feature_count_, clf.feature_log_prob_), axis=0),\n",
    "            index=['d_count', 'r_count', 'd_log_proba', 'r_log_proba'],\n",
    "            columns=vectorizer.get_feature_names_out()\n",
    "            )\\\n",
    "    .T.sort_values(by='r_log_proba')\\\n",
    "    .head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizing again here for convenience. Let's play with the parameters and see what it does to the performance of the classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "        stop_words='english', # 'english' if not custom list\n",
    "        ngram_range=(1,2),\n",
    "        binary=False,\n",
    "        min_df=0.0\n",
    "    )\n",
    "\n",
    "X = vectorizer.fit_transform(speeches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I run multiple kinds of classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  score_time  test_accuracy  test_precision  test_recall  \\\n",
       "mean       0.0         0.0           0.84            0.89         0.81   \n",
       "std        0.0         0.0           0.12            0.16         0.15   \n",
       "\n",
       "      test_f1  \n",
       "mean     0.84  \n",
       "std      0.12  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X,y)\n",
    "scores = cross_validate(clf, X, y, scoring=scoring, cv=4)\n",
    "pd.DataFrame(scores).describe().round(2)[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  score_time  test_accuracy  test_precision  test_recall  \\\n",
       "mean      0.11        0.00           0.76            0.85         0.72   \n",
       "std       0.02        0.01           0.12            0.11         0.39   \n",
       "\n",
       "      test_f1  \n",
       "mean     0.70  \n",
       "std      0.28  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(C=1e9, solver='lbfgs', max_iter=4000)\n",
    "clf.fit(X,y)\n",
    "scores = cross_validate(clf, X, y, scoring=scoring, cv=4)\n",
    "pd.DataFrame(scores).describe().round(2)[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  score_time  test_accuracy  test_precision  test_recall  \\\n",
       "mean      0.02         0.0           0.76            0.78         0.77   \n",
       "std       0.00         0.0           0.07            0.02         0.19   \n",
       "\n",
       "      test_f1  \n",
       "mean     0.77  \n",
       "std      0.09  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Support Vector Classification.\n",
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC(dual='auto')\n",
    "clf.fit(X, y)\n",
    "scores = cross_validate(clf, X, y, scoring=scoring, cv=4)\n",
    "pd.DataFrame(scores).describe().round(2)[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehtad/Development/media-vs-polls/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/mehtad/Development/media-vs-polls/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.52</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  score_time  test_accuracy  test_precision  test_recall  \\\n",
       "mean      1.52        0.01           0.64            0.42         0.46   \n",
       "std       0.04        0.00           0.24            0.50         0.54   \n",
       "\n",
       "      test_f1  \n",
       "mean     0.43  \n",
       "std      0.50  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multi-layer perceptron (a type of Neural Network Â¯\\_(ãƒ„)_/Â¯)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier()\n",
    "clf.fit(X,y)\n",
    "scores = cross_validate(clf, X, y, scoring=scoring, cv=4)\n",
    "pd.DataFrame(scores).describe().round(2)[1:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
